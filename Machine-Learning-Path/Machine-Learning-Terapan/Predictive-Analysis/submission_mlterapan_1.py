# -*- coding: utf-8 -*-
"""submission_mlterapan_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mmCbD4mUvrSUhJdqYdhlCia1K5a55jtq

# **Data Diri**

---
(Peserta Kampus merdeka - Student Indepentdent)


Nama : Gusti Muhammad Aulia Nur Sulthan

Alamat :  Kabupaten Hulu Sungai Selatan, Kalimantan Selatan

SIB Id : M247R6216

SIB Email : M247R6216@dicoding.org	

SIB Group : M3

# Introduction :
Topik dalam projek ini tentang klasifikasi stroke terhadap manusia dengan 12 attribut. Topik ini dibuat untuk Submission 1 Machine Learning Terapan Dicoding.

# Data Loading

## Download Package
install package `opendatasets` yang digunakan untuk mendownload dataset dari google
"""

! pip install opendatasets

! pip install plotly

"""## Importing Libraries 
Library yang digunakan dalam notebook ini
"""

# Commented out IPython magic to ensure Python compatibility.
import opendatasets as od

import pandas as pd
from matplotlib import pyplot as plt
import seaborn as sns
import plotly.express as px

from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

from sklearn.preprocessing import StandardScaler, OrdinalEncoder
from sklearn.model_selection import train_test_split

import time
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

plt.style.use('seaborn')
# %matplotlib inline

"""## Download Dataset """

od.download('https://www.kaggle.com/fedesoriano/stroke-prediction-dataset')

"""### Dataset Information 

![](image/dataset.png)

**Information :**

Type | Information
--- | ---
Source | [Kaggle Dataset : Stroke Prediction Dataset](https://www.kaggle.com/fedesoriano/stroke-prediction-dataset)
License | Data files Â© Original Authors
Category | Health
Usage Rating | 10.0 (Gold)
File Type and Size | CSV (317 kb)

# Data Understanding

### Read Dataset
"""

df = pd.read_csv('stroke-prediction-dataset/healthcare-dataset-stroke-data.csv')
df.head()

"""### Atribute Information

Attribute | Information
--- | ---
id | unique indentifier
gender | gender patient ('Male', 'Female', or 'Other')
age | age of the patient
hypertension | 0 if the patient doesn't have hypertension, 1 if the patient has hypertension
heart_disease | 0 if the patient doesn't have any heart diseases, 1 if the patient has a heart disease
ever_married | "No" or "Yes"
work_type | "children", "Govt_jov", "Never_worked", "Private" or "Self-employed"
Residence_type | "Rural" or "Urban"
avg_glucose_level | average glucose level in blood
bmi | body mass index
smoking_status | "formerly smoked", "never smoked", "smokes" or "Unknown"*
stroke | 1 if the patient had a stroke or 0 if not


**Note: "Unknown" in smoking_status means that the information is unavailable for this patient**

### Check dataset information
"""

df.info()

"""dalam tabel informasi dataset terdapat :
* 7 numeric variable diantaranya 4 bertipe int 3 bertipe float
* 5 non numeric variable bertipe object

### Description dataset
#### Deskripsi data Numeric
"""

df.describe().T

"""#### Deskrispi data object"""

df.describe(include=object).T

"""### Check Missing Value"""

df.isna().sum()

"""Terlihat di tabel ada `missing value` pada attribute **bmi**

### Check unique value
"""

df.nunique()

"""### Check Duplicate"""

df.duplicated().sum()

"""Tidak ada data duplikat

### Check stroke diagnose
"""

stroke = df['stroke']

print(f'Jumlah pasien yang tidak stroke : {stroke.value_counts()[0]} ({round(stroke.value_counts(normalize=True)[0]*100,2)}%)')
print(f'Jumlah pasien yang stroke : {stroke.value_counts()[1]} ({round(stroke.value_counts(normalize=True)[1]*100,2)}%)')

"""Note* 
<br>Sesuai keterangan pada `attribute information` yang mana
* `0` adalah pasien yang tidak memiliki stroke
* `1` adalah pasien yang memiliki storke
"""

print(f'Jumlah Data {df.shape[0]} dan memiliki {df.shape[1]} Attributes')

"""# Exploratory Data Analysis (EDA)

## Data Cleaning

karena tidak ada data duplikat jadi kolom `id` tidak diperlukan maka di drop
"""

df.drop('id', axis=1, inplace=True)

"""pada column gender terdapat nilai `Other` harus di drop karena data tersebut tidaklah relevan dengan gender manusia"""

df['gender'].value_counts()

df.drop(df[(df['gender']== 'Other')].index, inplace=True)

df['gender'].value_counts()

df.shape

"""untuk mempermudah dalam data preprocessing nama kolom data diubah menjadi huruf kecil dan mengganti `spasi kosong` atau `&` menjadi `_`"""

df.columns = df.columns.str.lower().str.replace('&', '_').str.replace(' ', '_')

"""dalam attribut `ever_married` value nya berisikan 
* Yes
* No

agar mempermudah kedepannya ubah value attribut `ever_married` menjadi biner `1` untuk `Yes` dan `0` untuk `No`
"""

df['ever_married'].value_counts()

df['ever_married'] = df['ever_married'].replace(['Yes', 'No'],[1, 0])

df['ever_married'].value_counts()

"""### Handling Missing Value
di Data understanding terdapat missing value pada attribut `bmi` body mass index saya akan mengisi missing value tersebut dengan rata-rata dari body mass index
"""

mean_bmi = df['bmi'].mean()
print(f'Rata - rata BMI : {round(mean_bmi,1)}')

df['bmi'] = df['bmi'].fillna(round(mean_bmi,1))

"""### Data Keseluruhan setelah di bersihkan"""

list_item = []
for col in df.columns:
    list_item.append([col, df[col].dtype, df[col].isna().sum(), 100*df[col].isna().sum()/len(df[col]), df[col].nunique(), df[col].unique()[:4]])
desc_df = pd.DataFrame(data=list_item, columns='Feature Data_Type Null_num Null_pct Unique_num Unique_Sample'.split())
desc_df

"""## Split Features

split attribut numerik dan kategorikal
"""

numerical_columns = ['age', 'avg_glucose_level', 'bmi']
categorical_columns = df.drop(['age', 'avg_glucose_level', 'bmi', 'stroke'],axis=1)

"""## Check Outliers
menggunakan boxplot dan attribut numeric
"""

for column in numerical_columns:
    sns.set(rc={"figure.figsize":(10, 10)})
    sns.boxplot(x=df[column])
    plt.title(column.upper(), fontsize=20, pad=10)
    plt.show()

"""Terlihat pada boxplot diatas ada attribut yang memiliki outlier maka akan saya hapus data yang outlier"""

print("Total data sebelum dihapus outliers: ", df.shape[0])

for column in numerical_columns:
    q1 = df[column].quantile(0.25)
    q3 = df[column].quantile(0.75)
    iqr = q3 - q1
    fence_low  = q1 - 1.5*iqr
    fence_high = q3 + 1.5*iqr
    df = df.loc[(df[column] > fence_low) & (df[column] < fence_high)]
print("Total data sebelum dihapus outliers: ", df.shape[0])

"""## Univariate Analysis

### Categorical Features
"""

for column in categorical_columns:
    count = df[column].value_counts()
    percent = 100*df[column].value_counts(normalize=True)
    new_df = pd.DataFrame({'Total data':count, 'Persentase':percent.round(1)})
    
    fig = count.plot(kind='bar', title=column, figsize=(15,15), rot=1, fontsize=15).get_figure()
    plt.title(column.upper(), fontsize=20, pad=10)
    plt.tight_layout()
    plt.savefig(f'{column}.png')
    plt.show()
    print(new_df, end="\n\n")

"""## Numeric Features"""

for column in numerical_columns:
    sns.set(rc={"figure.figsize":(15, 15)})
    sns.histplot(data=df[column], edgecolor='k',binwidth=1)
    plt.title(column.upper(), fontsize=20, pad=10)
    plt.tight_layout()
    plt.savefig(f'{column}.png')
    plt.show()

"""### Label Features"""

stroke_data = pd.DataFrame(df['stroke'].value_counts())

figures = px.pie(data_frame=stroke_data,
                 values='stroke',
                 names=['Stroke','Not Stroke'],
                 hole=0.4,
                 color_discrete_sequence=["#FF7171","#9FD8DF"],
                 labels={'label':'Stroke','Stroke':'No. Of Samples'})

figures.update_layout(font_family='Open Sans',
                      title=dict(text='Distribusi attribute pada kolom Stroke',
                                 font=dict(color="#333",size=20)))

figures.update_traces(textposition='outside', textinfo='percent+label')

figures.show()

"""## Multivariate Analysis"""

for column in categorical_columns:
    sns.catplot(x=column, y="stroke", kind="bar", dodge=False, height = 4, aspect = 2,  data=df, palette="Set3")
    plt.title(f'Jumlah rata-rata Stroke terhadap - {column.upper()}', size=20, pad=20)
    plt.tight_layout()
    plt.savefig(f'variate_{column}.png')
    plt.show()

sns.pairplot(df, diag_kind="kde")
plt.tight_layout()
plt.savefig(f'numeric.png')
plt.show()

"""## Check Corelation"""

plt.figure(figsize=(15,8))
sns.heatmap(df.corr(), annot=True)
plt.title('Correlation Matrix Fiture Numerik', size=20, pad=20)
plt.show()

"""Terlihat feature `avg_glucose_level` 0.00022 dan sangat jauh dari label kita `stroke` sehingga kita drop"""

df.drop(['avg_glucose_level'], axis=1, inplace=True)

print('Kolom yang tersisa :')
x=0
for i in df.columns:
    x +=1
    print(f'{x}. {i}')

"""# Data Preparation

### Encode feature object ke numerik
"""

encoder = OrdinalEncoder()

categorical_columns = df.select_dtypes('object').columns
df[categorical_columns] = encoder.fit_transform(df[categorical_columns])

"""Ubah semua type data menjadi float"""

df = df.astype('float64')
df.info()

"""### Train-Test-Split
Split data menjadi dua Train dan Test
"""

X = df.drop(['stroke'], axis=1)
y = df['stroke']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,
                                                   random_state=42)

"""### Standarization"""

scaler = StandardScaler()
scaler.fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)

"""# Model Deployment
Model yang akan digunakan adalah :
* Suport Vector Clasification
* Decision Tree
* Random Forest
"""

# Suport Vector Clasification
svm = SVC()

# Decision Tree
dt = DecisionTreeClassifier()

# Random Forest
rf = RandomForestClassifier()

print('Model dibuat')

"""#### Fungsi untuk melatih dan melihat seberapa besar acuracy yang dimiliki model"""

def model_test(model):
  start = time.time()
  model.fit(X_train, y_train)
  end = time.time()
  time_spent = end-start
  pred = model.predict(X_test)
  acc = accuracy_score(y_test, pred)
  print(confusion_matrix(y_test, pred))
  print("Training time spend : {} seconds".format(round(time_spent, 3)))
  print("Accuracy            : {}".format(round(acc, 3)))
  print(classification_report(y_test, pred))

"""## Evaluasi Model"""

print("Suport Vector Machine\n")
model_test(svm)

print("Decision Tree\n")
model_test(dt)

print("Random forest\n")
model_test(rf)

evaluation = pd.DataFrame(columns=['train', 'test'], index=["SVM",
                                                            "Decision Tree", 
                                                            "Random Forest"])
model_dict = {
    "SVM": svm,
    "Decision Tree": dt,
    "Random Forest": rf
}
for name, model in model_dict.items():
    evaluation.loc[name, 'train'] = accuracy_score(y_true=y_train, 
                                                   y_pred=model.predict(X_train))
    evaluation.loc[name, 'test'] = accuracy_score(y_true=y_test, 
                                                  y_pred=model.predict(X_test))
 
evaluation

evaluation.plot(kind='barh', figsize=(15, 15), fontsize=15)
plt.title('Evaluasi Model', fontsize=20, pad=20)
plt.tight_layout()
plt.savefig(f'evaluasi.png')
plt.show()

