# -*- coding: utf-8 -*-
"""subsmission NLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mr35cgkkHjtzRUipiaCq9keQH9xrZQsJ
"""

# import library yang diperlukan

import tensorflow as tf
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

import pandas as pd

df = pd.read_csv('clickbait_data.csv')
df.tail()

# membagi attribut dan label
text = df['headline'].values
y = df['clickbait'].values

# split menggunakan train_test_split
text_latih, text_test, y_latih, y_test = train_test_split(text, y, test_size=0.2)

vocab_size = 5000
maxlen = 500
embbedding_size = 32

# Tokenize text (padding dan sequences)
tokenizer = Tokenizer(num_words=vocab_size, oov_token='x')
tokenizer.fit_on_texts(text)

sekuens_latih = tokenizer.texts_to_sequences(text_latih)
sekuens_test = tokenizer.texts_to_sequences(text_test)

padded_latih = pad_sequences(sekuens_latih, maxlen=maxlen)
padded_test = pad_sequences(sekuens_test, maxlen=maxlen)

# latih model
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(vocab_size, embbedding_size, input_length=maxlen),
    tf.keras.layers.LSTM(32, return_sequences=True),
    tf.keras.layers.GlobalAveragePooling1D(),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(1, activation='sigmoid')
])
model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])

# Callback

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy','val_accuracy')>0.8):
      print("\nAkurasi telah mencapai >80%!")
      self.model.stop_training = True
callbacks = myCallback()

num_epochs = 20
history = model.fit(padded_latih, y_latih, epochs=num_epochs, batch_size=512, 
                    validation_data=(padded_test, y_test), verbose=2, callbacks=[callbacks])

import matplotlib.pyplot as plt

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
x = range(1, len(acc) + 1)

plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(x, acc, 'b', label='Training acc')
plt.plot(x, val_acc, 'r', label='Validation acc')
plt.title('Training and validation accuracy')
plt.legend()
plt.subplot(1, 2, 2)
plt.plot(x, loss, 'b', label='Training loss')
plt.plot(x, val_loss, 'r', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()
plt.show()